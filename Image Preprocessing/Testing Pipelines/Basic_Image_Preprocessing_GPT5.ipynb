{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "297fcba2",
   "metadata": {},
   "source": [
    "# GPT 5 Testing\n",
    "## Basic Image Preprocessing using GPT5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55fe3c0",
   "metadata": {},
   "source": [
    "## Plan: Preprocess SIPaKMeD cropped images\n",
    "We will:\n",
    "- Use the cropped class folders in `Dataset/Raw Dataset/SipakMed Dataset/*`.\n",
    "- Standardize each image to a square canvas and resize to 256x256.\n",
    "- Apply gentle denoising (median), gray-world white balance, and CLAHE on luminance for contrast.\n",
    "- Optionally apply light unsharp masking.\n",
    "- Preserve class subfolders and save as PNG.\n",
    "\n",
    "Output will be written to: `Dataset/Preprocessed_SipakMed_256_GW_CLAHE_USM/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "221c2f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  c:\\Meet\\Projects\\Project_8_Phoenix_Cervical Cancer Image Classification\\Project-Phoenix\\Dataset\\Raw Dataset\\SipakMed Dataset\n",
      "Output: c:\\Meet\\Projects\\Project_8_Phoenix_Cervical Cancer Image Classification\\Project-Phoenix\\Dataset\\Preprocessed_SipakMed_256_GW_CLAHE_USM\n"
     ]
    }
   ],
   "source": [
    "# Imports and configuration\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import gc\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import cv2  # Preferred for image ops\n",
    "except Exception:\n",
    "    cv2 = None\n",
    "\n",
    "try:\n",
    "    from PIL import Image, ImageFilter, ImageOps\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"Pillow is required. Please install with `pip install pillow`.\\n\" + str(e))\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except Exception:\n",
    "    def tqdm(x, **kwargs):\n",
    "        return x\n",
    "\n",
    "# Absolute paths (edit if needed)\n",
    "DATASET_BASE = Path(r\"c:/Meet/Projects/Project_8_Phoenix_Cervical Cancer Image Classification/Project-Phoenix/Dataset\")\n",
    "INPUT_DIR = DATASET_BASE / \"Raw Dataset\" / \"SipakMed Dataset\"\n",
    "# New output folder name\n",
    "OUTPUT_DIR = DATASET_BASE / \"Preprocessed_SipakMed_256_GW_CLAHE_USM\"\n",
    "\n",
    "# Preprocessing parameters\n",
    "TARGET_SIZE = 256  # final square size\n",
    "MEDIAN_KSIZE = 3   # gentle denoising\n",
    "CLAHE_CLIP_LIMIT = 1.3\n",
    "CLAHE_TILE_GRID = (8, 8)\n",
    "APPLY_UNSHARP = True\n",
    "UNSHARP_AMOUNT = 0.35  # 0..1 typical\n",
    "UNSHARP_RADIUS = 0.9\n",
    "# Blend factor for white balance (0=no WB, 1=full WB)\n",
    "WB_BLEND = 0.7\n",
    "\n",
    "# Threading\n",
    "MAX_WORKERS = max(4, os.cpu_count() or 4)\n",
    "\n",
    "# Valid image extensions\n",
    "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n",
    "\n",
    "print(f\"Input:  {INPUT_DIR}\")\n",
    "print(f\"Output: {OUTPUT_DIR}\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74bb61e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers: IO and preprocessing primitives\n",
    "\n",
    "def is_image_file(p: Path) -> bool:\n",
    "    return p.suffix.lower() in IMG_EXTS\n",
    "\n",
    "\n",
    "def read_image_rgb(path: Path) -> np.ndarray:\n",
    "    \"\"\"Read image as RGB uint8 array. Handles alpha by compositing on white.\"\"\"\n",
    "    with Image.open(path) as im:\n",
    "        if im.mode in (\"RGBA\", \"LA\"):\n",
    "            bg = Image.new(\"RGBA\", im.size, (255, 255, 255, 255))\n",
    "            im = Image.alpha_composite(bg, im.convert(\"RGBA\")).convert(\"RGB\")\n",
    "        elif im.mode != \"RGB\":\n",
    "            im = im.convert(\"RGB\")\n",
    "        arr = np.array(im, dtype=np.uint8)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def save_png_rgb(path: Path, arr: np.ndarray):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    img = Image.fromarray(arr.astype(np.uint8), mode=\"RGB\")\n",
    "    img.save(path, format=\"PNG\", optimize=True)\n",
    "\n",
    "\n",
    "def compute_border_fill_color(img_rgb: np.ndarray) -> tuple:\n",
    "    \"\"\"Estimate a pleasant pad color using border median.\"\"\"\n",
    "    h, w, _ = img_rgb.shape\n",
    "    border = np.concatenate([\n",
    "        img_rgb[0, :, :], img_rgb[-1, :, :],\n",
    "        img_rgb[:, 0, :], img_rgb[:, -1, :]\n",
    "    ], axis=0)\n",
    "    med = np.median(border, axis=0)\n",
    "    return tuple(int(x) for x in med)\n",
    "\n",
    "\n",
    "def resize_with_padding(img_rgb: np.ndarray, target: int) -> np.ndarray:\n",
    "    h, w, _ = img_rgb.shape\n",
    "    scale = min(target / h, target / w)\n",
    "    nh, nw = max(1, int(round(h * scale))), max(1, int(round(w * scale)))\n",
    "\n",
    "    if cv2 is not None:\n",
    "        resized = cv2.resize(img_rgb, (nw, nh), interpolation=cv2.INTER_AREA)\n",
    "    else:\n",
    "        resized = np.array(Image.fromarray(img_rgb).resize((nw, nh), Image.Resampling.LANCZOS))\n",
    "\n",
    "    pad_color = compute_border_fill_color(img_rgb)\n",
    "    canvas = np.full((target, target, 3), pad_color, dtype=np.uint8)\n",
    "    y0 = (target - nh) // 2\n",
    "    x0 = (target - nw) // 2\n",
    "    canvas[y0:y0+nh, x0:x0+nw] = resized\n",
    "    return canvas\n",
    "\n",
    "\n",
    "def median_denoise(img_rgb: np.ndarray, ksize: int = 3) -> np.ndarray:\n",
    "    if ksize and ksize >= 3:\n",
    "        if cv2 is not None:\n",
    "            return cv2.medianBlur(img_rgb, ksize)\n",
    "        else:\n",
    "            return np.array(Image.fromarray(img_rgb).filter(ImageFilter.MedianFilter(size=ksize)))\n",
    "    return img_rgb\n",
    "\n",
    "\n",
    "def gray_world_white_balance(img_rgb: np.ndarray) -> np.ndarray:\n",
    "    # Gray-world assumption with blending\n",
    "    img = img_rgb.astype(np.float32)\n",
    "    means = img.reshape(-1, 3).mean(axis=0)\n",
    "    gray = float(means.mean()) + 1e-6\n",
    "    gains = gray / (means + 1e-6)\n",
    "    corrected = np.clip(img * gains, 0, 255)\n",
    "    blended = (1.0 - WB_BLEND) * img + WB_BLEND * corrected\n",
    "    return blended.astype(np.uint8)\n",
    "\n",
    "\n",
    "def clahe_on_luminance(img_rgb: np.ndarray, clip: float = 2.0, tile=(8, 8)) -> np.ndarray:\n",
    "    if cv2 is None:\n",
    "        # Fallback: mild autocontrast on Y channel approximation\n",
    "        im = Image.fromarray(img_rgb, 'RGB').convert('YCbCr')\n",
    "        y, cb, cr = im.split()\n",
    "        y = ImageOps.autocontrast(y, cutoff=1)\n",
    "        im = Image.merge('YCbCr', (y, cb, cr)).convert('RGB')\n",
    "        return np.array(im)\n",
    "    lab = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=CLAHE_CLIP_LIMIT, tileGridSize=CLAHE_TILE_GRID)\n",
    "    l2 = clahe.apply(l)\n",
    "    lab2 = cv2.merge((l2, a, b))\n",
    "    rgb = cv2.cvtColor(lab2, cv2.COLOR_LAB2RGB)\n",
    "    return rgb\n",
    "\n",
    "\n",
    "def unsharp_mask(img_rgb: np.ndarray, radius: float = 1.0, amount: float = 0.6) -> np.ndarray:\n",
    "    if amount <= 0:\n",
    "        return img_rgb\n",
    "    if cv2 is not None:\n",
    "        # Convert radius (sigma) to kernel size; ensure odd\n",
    "        sigma = max(0.1, float(radius))\n",
    "        k = int(round(sigma * 6)) | 1\n",
    "        blur = cv2.GaussianBlur(img_rgb, (k, k), sigmaX=sigma)\n",
    "        # img * (1+amount) - blur * amount\n",
    "        sharp = cv2.addWeighted(img_rgb, 1.0 + amount, blur, -amount, 0)\n",
    "        return np.clip(sharp, 0, 255).astype(np.uint8)\n",
    "    else:\n",
    "        pil = Image.fromarray(img_rgb)\n",
    "        pil = pil.filter(ImageFilter.UnsharpMask(radius=radius, percent=int(amount*200), threshold=2))\n",
    "        return np.array(pil)\n",
    "\n",
    "\n",
    "def pipeline(img_rgb: np.ndarray) -> np.ndarray:\n",
    "    # 1) Gentle denoise\n",
    "    x = median_denoise(img_rgb, MEDIAN_KSIZE)\n",
    "    # 2) White balance (gray-world)\n",
    "    x = gray_world_white_balance(x)\n",
    "    # 3) Local contrast (CLAHE on luminance)\n",
    "    x = clahe_on_luminance(x)\n",
    "    # 4) Resize with padding to square\n",
    "    x = resize_with_padding(x, TARGET_SIZE)\n",
    "    # 5) Optional light sharpening\n",
    "    if APPLY_UNSHARP:\n",
    "        x = unsharp_mask(x, UNSHARP_RADIUS, UNSHARP_AMOUNT)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46999abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5015 images under c:\\Meet\\Projects\\Project_8_Phoenix_Cervical Cancer Image Classification\\Project-Phoenix\\Dataset\\Raw Dataset\\SipakMed Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 5015/5015 [01:44<00:00, 48.06it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Saved: 5015, Failed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build file list and run preprocessing\n",
    "\n",
    "def find_images(base: Path):\n",
    "    files = []\n",
    "    for p in base.rglob('*'):\n",
    "        if p.is_file() and is_image_file(p):\n",
    "            files.append(p)\n",
    "    return files\n",
    "\n",
    "\n",
    "def dest_from_src(src: Path) -> Path:\n",
    "    rel = src.relative_to(INPUT_DIR)\n",
    "    # Keep class folders, force .png extension\n",
    "    return OUTPUT_DIR / rel.with_suffix('.png')\n",
    "\n",
    "\n",
    "def process_one(src: Path) -> tuple:\n",
    "    dst = dest_from_src(src)\n",
    "    try:\n",
    "        arr = read_image_rgb(src)\n",
    "        out = pipeline(arr)\n",
    "        save_png_rgb(dst, out)\n",
    "        return (True, src, None)\n",
    "    except Exception as e:\n",
    "        return (False, src, str(e))\n",
    "\n",
    "\n",
    "all_imgs = find_images(INPUT_DIR)\n",
    "print(f\"Found {len(all_imgs)} images under {INPUT_DIR}\")\n",
    "\n",
    "ok = 0\n",
    "fail = 0\n",
    "errors = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "    futures = [ex.submit(process_one, p) for p in all_imgs]\n",
    "    for fut in tqdm(as_completed(futures), total=len(futures), desc='Preprocessing'):\n",
    "        success, src, err = fut.result()\n",
    "        if success:\n",
    "            ok += 1\n",
    "        else:\n",
    "            fail += 1\n",
    "            errors.append((src, err))\n",
    "\n",
    "print(f\"Done. Saved: {ok}, Failed: {fail}\")\n",
    "if fail:\n",
    "    print(\"Sample errors:\")\n",
    "    for s, e in errors[:5]:\n",
    "        print(\"-\", s, \"->\", e)\n",
    "\n",
    "# Free memory\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
