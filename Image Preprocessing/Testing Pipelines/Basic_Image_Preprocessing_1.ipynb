{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ccfd19f",
   "metadata": {},
   "source": [
    "# Basic Image Preprocessing_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d42a958",
   "metadata": {},
   "source": [
    "### Perona–Malik Diffusion (PMD) Filter\n",
    "PMD is a type of anisotropic diffusion that reduces image noise while preserving important edges and structures, unlike simple Gaussian blur which blurs everything indiscriminately.\n",
    "  \n",
    "In medical imaging tasks like Pap smear classification, PMD helps keep key details (like nuclei edges) intact while smoothing out grainy background noise.\n",
    "\n",
    "### Contrast-Limited Adaptive Histogram Equalization (CLAHE)\n",
    "CLAHE enhances local contrast by dividing the image into small tiles and applying histogram equalization within each. It prevents over-amplifying noise through a clip limit .\n",
    "  \n",
    "Particularly effective on unevenly illuminated images like cervical cells, it makes subtle morphological features more visible without introducing artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f14fea",
   "metadata": {},
   "source": [
    "### Why Combine PMD + CLAHE?\n",
    "The hybrid PMD → CLAHE pipeline has been empirically shown to significantly improve CNN-based cervical cell classification:\n",
    "  \n",
    "Boosts in accuracy (up to ~13.6%), precision, recall, and F1‑score have been reported when using this combined preprocessing, especially with models like ResNet‑50, EfficientNet, and DenseNet \n",
    "IJEECS.\n",
    "\n",
    "We process each RGB channel separately: apply PMD and CLAHE per channel, then recombine to preserve color balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5b35988",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing im_Dyskeratotic: 100%|██████████| 1626/1626 [00:48<00:00, 33.26it/s]\n",
      "Processing im_Koilocytotic: 100%|██████████| 1650/1650 [00:59<00:00, 27.94it/s]\n",
      "Processing im_Metaplastic: 100%|██████████| 1586/1586 [00:56<00:00, 27.97it/s]\n",
      "Processing im_Parabasal: 100%|██████████| 1574/1574 [00:51<00:00, 30.65it/s]\n",
      "Processing im_Superficial-Intermediate: 100%|██████████| 1662/1662 [00:55<00:00, 29.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All classes processed and saved to Preprocessed Dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Base directories\n",
    "RAW_DATA_DIR = Path(\"../Dataset/Raw Dataset/SipakMed Dataset\")\n",
    "PREPROCESSED_DATA_DIR = Path(\"../Dataset/Preprocessed Dataset\")\n",
    "\n",
    "# Get all class folders\n",
    "classes = [d for d in RAW_DATA_DIR.iterdir() if d.is_dir()]\n",
    "\n",
    "def extract_and_save_crops(class_path, class_name):\n",
    "    inner_dir = class_path / class_name  # e.g., im_Dyskeratotic/im_Dyskeratotic\n",
    "    output_dir = PREPROCESSED_DATA_DIR / class_name\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Get .dat files for cyt/nuc\n",
    "    dat_files = [f for f in inner_dir.glob(\"*.dat\") if \"_cyt\" in f.name or \"_nuc\" in f.name]\n",
    "\n",
    "    for dat_path in tqdm(dat_files, desc=f\"Processing {class_name}\"):\n",
    "        image_id = dat_path.stem.split(\"_\")[0]  # '001'\n",
    "        image_path = inner_dir / f\"{image_id}.bmp\"\n",
    "\n",
    "        if not image_path.exists():\n",
    "            print(f\"Image not found for {dat_path.name}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        img = cv2.imread(str(image_path))\n",
    "        if img is None:\n",
    "            print(f\"Failed to load image: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Read (x, y) points from .dat file\n",
    "        with open(dat_path, \"r\") as f:\n",
    "            coords = [list(map(float, line.strip().split(\",\"))) for line in f if \",\" in line]\n",
    "\n",
    "        if len(coords) < 3:\n",
    "            print(f\"Invalid polygon in {dat_path.name}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        points = np.array(coords, dtype=np.int32)\n",
    "        x, y, w, h = cv2.boundingRect(points)\n",
    "\n",
    "        # Crop and resize\n",
    "        crop = img[y:y+h, x:x+w]\n",
    "        resized_crop = cv2.resize(crop, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Save cropped image\n",
    "        label = \"cyt\" if \"_cyt\" in dat_path.name else \"nuc\"\n",
    "        save_name = f\"{image_id}_{label}_{dat_path.stem.split('_')[-1]}.png\"\n",
    "        save_path = output_dir / save_name\n",
    "        cv2.imwrite(str(save_path), resized_crop)\n",
    "\n",
    "# Loop through all classes and process\n",
    "for class_dir in classes:\n",
    "    class_name = class_dir.name  # e.g., im_Dyskeratotic\n",
    "    extract_and_save_crops(class_dir, class_name)\n",
    "\n",
    "print(\"✅ All classes processed and saved to Preprocessed Dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89150fbd",
   "metadata": {},
   "source": [
    "## Basic Image Processing and parsing polygon from .dat files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af678df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing im_Dyskeratotic: 100%|██████████| 1626/1626 [00:56<00:00, 28.86it/s]\n",
      "Processing im_Koilocytotic: 100%|██████████| 1650/1650 [00:58<00:00, 28.18it/s]\n",
      "Processing im_Metaplastic: 100%|██████████| 1586/1586 [00:56<00:00, 27.86it/s]\n",
      "Processing im_Parabasal: 100%|██████████| 1574/1574 [00:50<00:00, 31.19it/s]\n",
      "Processing im_Superficial-Intermediate: 100%|██████████| 1662/1662 [00:56<00:00, 29.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All classes processed and saved to Preprocessed SipakMed_2 (with PMD & CLAHE).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Base directories\n",
    "RAW_DATA_DIR = Path(\"../Dataset/Raw Dataset/SipakMed Dataset\")\n",
    "PREPROCESSED_DATA_DIR = Path(\"../Dataset/Preprocessed SipakMed_2\")  \n",
    "\n",
    "# Ensure output dir exists\n",
    "PREPROCESSED_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Get all class folders\n",
    "classes = [d for d in RAW_DATA_DIR.iterdir() if d.is_dir()]\n",
    "\n",
    "def apply_clahe(img, clip_limit=2.0, tile_grid_size=(8,8)):\n",
    "    \"\"\"Apply CLAHE to all 3 channels.\"\"\"\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "    if len(img.shape) == 2:\n",
    "        return clahe.apply(img)\n",
    "    # For RGB: apply channel-wise\n",
    "    channels = cv2.split(img)\n",
    "    clahe_channels = [clahe.apply(c) for c in channels]\n",
    "    return cv2.merge(clahe_channels)\n",
    "\n",
    "def apply_median_filter(img, ksize=3):\n",
    "    \"\"\"Apply median filter (PMD-style) channel wise.\"\"\"\n",
    "    if len(img.shape) == 2:\n",
    "        return cv2.medianBlur(img, ksize)\n",
    "    return cv2.merge([cv2.medianBlur(img[:,:,i], ksize) for i in range(img.shape[2])])\n",
    "\n",
    "def extract_and_save_crops(class_path, class_name):\n",
    "    inner_dir = class_path / class_name\n",
    "    output_dir = PREPROCESSED_DATA_DIR / class_name\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Get .dat files for cyt/nuc\n",
    "    dat_files = [f for f in inner_dir.glob(\"*.dat\") if \"_cyt\" in f.name or \"_nuc\" in f.name]\n",
    "\n",
    "    for dat_path in tqdm(dat_files, desc=f\"Processing {class_name}\"):\n",
    "        image_id = dat_path.stem.split(\"_\")[0]\n",
    "        image_path = inner_dir / f\"{image_id}.bmp\"\n",
    "\n",
    "        if not image_path.exists():\n",
    "            print(f\"Image not found for {dat_path.name}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        img = cv2.imread(str(image_path))\n",
    "        if img is None:\n",
    "            print(f\"Failed to load image: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Parse polygon from .dat\n",
    "        with open(dat_path, \"r\") as f:\n",
    "            coords = [list(map(float, line.strip().split(\",\"))) for line in f if \",\" in line]\n",
    "        if len(coords) < 3:\n",
    "            print(f\"Invalid polygon in {dat_path.name}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        points = np.array(coords, dtype=np.int32)\n",
    "        x, y, w, h = cv2.boundingRect(points)\n",
    "\n",
    "        # Crop region of interest\n",
    "        crop = img[y:y+h, x:x+w]\n",
    "\n",
    "        # --- Optional PMD: Median filter for denoising\n",
    "        crop_pmd = apply_median_filter(crop, ksize=3)\n",
    "\n",
    "        # --- Optional: Morphological opening to smooth small noise (can be tuned)\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        crop_pmd = cv2.morphologyEx(crop_pmd, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # --- CLAHE for contrast enhancement\n",
    "        crop_clahe = apply_clahe(crop_pmd)\n",
    "\n",
    "        # Resize\n",
    "        resized_crop = cv2.resize(crop_clahe, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Save processed crop\n",
    "        label = \"cyt\" if \"_cyt\" in dat_path.name else \"nuc\"\n",
    "        save_name = f\"{image_id}_{label}_{dat_path.stem.split('_')[-1]}.png\"\n",
    "        save_path = output_dir / save_name\n",
    "        cv2.imwrite(str(save_path), resized_crop)\n",
    "\n",
    "# Loop through all classes and process\n",
    "for class_dir in classes:\n",
    "    class_name = class_dir.name\n",
    "    extract_and_save_crops(class_dir, class_name)\n",
    "\n",
    "print(\"✅ All classes processed and saved to Preprocessed SipakMed_2 (with PMD & CLAHE).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c053f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
