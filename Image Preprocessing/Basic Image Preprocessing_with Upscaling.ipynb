{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9f56d4f",
   "metadata": {},
   "source": [
    "# Image Preprocessing with Upscaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d060128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing im_Dyskeratotic: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1626/1626 [01:00<00:00, 26.81it/s]\n",
      "Processing im_Koilocytotic: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1650/1650 [00:59<00:00, 27.94it/s]\n",
      "Processing im_Metaplastic: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1586/1586 [00:56<00:00, 27.97it/s]\n",
      "Processing im_Parabasal: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1574/1574 [00:51<00:00, 30.64it/s]\n",
      "Processing im_Superficial-Intermediate: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1662/1662 [00:55<00:00, 29.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All classes processed and saved to Preprocessed Dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Base directories\n",
    "RAW_DATA_DIR = Path(\"../Dataset/Raw Dataset/SipakMed Dataset\")\n",
    "PREPROCESSED_DATA_DIR = Path(\"../Dataset/Preprocessed Enhanced Dataset\")\n",
    "\n",
    "# Get all class folders\n",
    "classes = [d for d in RAW_DATA_DIR.iterdir() if d.is_dir()]\n",
    "\n",
    "def enhance_image_resolution(image):\n",
    "    \"\"\"\n",
    "    Enhance image resolution using various techniques\n",
    "    \"\"\"\n",
    "    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    lab[:,:,0] = clahe.apply(lab[:,:,0])\n",
    "    enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    # Apply unsharp masking for sharpening\n",
    "    gaussian = cv2.GaussianBlur(enhanced, (0, 0), 2.0)\n",
    "    unsharp_mask = cv2.addWeighted(enhanced, 1.5, gaussian, -0.5, 0)\n",
    "    \n",
    "    # Denoise while preserving edges\n",
    "    denoised = cv2.bilateralFilter(unsharp_mask, 9, 75, 75)\n",
    "    \n",
    "    return denoised\n",
    "\n",
    "def crop_or_pad_to_square(image, target_size=256):\n",
    "    \"\"\"\n",
    "    Crop or pad image to square while maintaining aspect ratio\n",
    "    \"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    if h == w:\n",
    "        # Already square, just resize\n",
    "        return cv2.resize(image, (target_size, target_size), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Make it square by cropping or padding\n",
    "    size = max(h, w)\n",
    "    \n",
    "    # Create a square canvas\n",
    "    if len(image.shape) == 3:\n",
    "        square_img = np.zeros((size, size, 3), dtype=image.dtype)\n",
    "    else:\n",
    "        square_img = np.zeros((size, size), dtype=image.dtype)\n",
    "    \n",
    "    # Calculate padding/cropping offsets\n",
    "    if h > w:\n",
    "        # Pad width (add to sides)\n",
    "        start_x = (size - w) // 2\n",
    "        square_img[:, start_x:start_x+w] = image\n",
    "    else:\n",
    "        # Pad height (add to top/bottom)\n",
    "        start_y = (size - h) // 2\n",
    "        square_img[start_y:start_y+h, :] = image\n",
    "    \n",
    "    # Resize to target size\n",
    "    return cv2.resize(square_img, (target_size, target_size), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "def center_crop_to_square(image, crop_size=None):\n",
    "    \"\"\"\n",
    "    Center crop image to square format\n",
    "    \"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    if crop_size is None:\n",
    "        crop_size = min(h, w)\n",
    "    \n",
    "    # Calculate center crop coordinates\n",
    "    start_y = (h - crop_size) // 2\n",
    "    start_x = (w - crop_size) // 2\n",
    "    \n",
    "    return image[start_y:start_y+crop_size, start_x:start_x+crop_size]\n",
    "\n",
    "def extract_and_save_crops(class_path, class_name):\n",
    "    inner_dir = class_path / class_name  # e.g., im_Dyskeratotic/im_Dyskeratotic\n",
    "    output_dir = PREPROCESSED_DATA_DIR / class_name\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Get .dat files for cyt/nuc\n",
    "    dat_files = [f for f in inner_dir.glob(\"*.dat\") if \"_cyt\" in f.name or \"_nuc\" in f.name]\n",
    "\n",
    "    for dat_path in tqdm(dat_files, desc=f\"Processing {class_name}\"):\n",
    "        image_id = dat_path.stem.split(\"_\")[0]  # '001'\n",
    "        image_path = inner_dir / f\"{image_id}.bmp\"\n",
    "\n",
    "        if not image_path.exists():\n",
    "            print(f\"Image not found for {dat_path.name}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        img = cv2.imread(str(image_path))\n",
    "        if img is None:\n",
    "            print(f\"Failed to load image: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Read (x, y) points from .dat file\n",
    "        with open(dat_path, \"r\") as f:\n",
    "            coords = [list(map(float, line.strip().split(\",\"))) for line in f if \",\" in line]\n",
    "\n",
    "        if len(coords) < 3:\n",
    "            print(f\"Invalid polygon in {dat_path.name}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        points = np.array(coords, dtype=np.int32)\n",
    "        x, y, w, h = cv2.boundingRect(points)\n",
    "\n",
    "        # Extract the region of interest with some padding\n",
    "        padding = 10  # Add some context around the cell\n",
    "        x1 = max(0, x - padding)\n",
    "        y1 = max(0, y - padding)\n",
    "        x2 = min(img.shape[1], x + w + padding)\n",
    "        y2 = min(img.shape[0], y + h + padding)\n",
    "        \n",
    "        crop = img[y1:y2, x1:x2]\n",
    "\n",
    "        # Enhance image resolution before processing\n",
    "        enhanced_crop = enhance_image_resolution(crop)\n",
    "\n",
    "        # Method 1: Center crop to square (preserves original resolution in center)\n",
    "        if min(enhanced_crop.shape[:2]) >= 224:\n",
    "            center_cropped = center_crop_to_square(enhanced_crop, 224)\n",
    "        else:\n",
    "            # If crop is too small, use padding method\n",
    "            center_cropped = crop_or_pad_to_square(enhanced_crop, 224)\n",
    "\n",
    "        # Method 2: Pad to square (preserves entire image)\n",
    "        padded_square = crop_or_pad_to_square(enhanced_crop, 256)\n",
    "\n",
    "        # Method 3: High-resolution version with padding\n",
    "        high_res_square = crop_or_pad_to_square(enhanced_crop, 512)\n",
    "\n",
    "        # Save different versions\n",
    "        label = \"cyt\" if \"_cyt\" in dat_path.name else \"nuc\"\n",
    "        base_name = f\"{image_id}_{label}_{dat_path.stem.split('_')[-1]}\"\n",
    "        \n",
    "        # Save center cropped version (224x224)\n",
    "        center_crop_path = output_dir / f\"{base_name}_center_crop.png\"\n",
    "        cv2.imwrite(str(center_crop_path), center_cropped)\n",
    "        \n",
    "        # Save padded square version (256x256)\n",
    "        padded_path = output_dir / f\"{base_name}_padded_256.png\"\n",
    "        cv2.imwrite(str(padded_path), padded_square)\n",
    "        \n",
    "        # Save high-resolution version (512x512)\n",
    "        high_res_path = output_dir / f\"{base_name}_high_res_512.png\"\n",
    "        cv2.imwrite(str(high_res_path), high_res_square)\n",
    "\n",
    "# Loop through all classes and process\n",
    "for class_dir in classes:\n",
    "    class_name = class_dir.name  # e.g., im_Dyskeratotic\n",
    "    extract_and_save_crops(class_dir, class_name)\n",
    "\n",
    "print(\"‚úÖ All classes processed and saved to Preprocessed Enhanced Dataset.\")\n",
    "print(\"üìÅ Output directory:\", PREPROCESSED_DATA_DIR)\n",
    "print(\"üîç Generated versions for each image:\")\n",
    "print(\"   - Center crop (224x224): Preserves center region at original resolution\")\n",
    "print(\"   - Padded square (256x256): Preserves entire image with padding\")\n",
    "print(\"   - High resolution (512x512): Enhanced resolution for detailed analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92238e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the different preprocessing methods by visualizing sample images\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "def compare_preprocessing_methods():\n",
    "    \"\"\"\n",
    "    Compare different preprocessing methods side by side\n",
    "    \"\"\"\n",
    "    # Find a sample processed image\n",
    "    sample_dirs = list(PREPROCESSED_DATA_DIR.glob(\"*/\"))\n",
    "    if not sample_dirs:\n",
    "        print(\"No processed images found. Please run the preprocessing first.\")\n",
    "        return\n",
    "    \n",
    "    sample_dir = sample_dirs[0]\n",
    "    \n",
    "    # Find different versions of the same image\n",
    "    image_files = list(sample_dir.glob(\"*_center_crop.png\"))\n",
    "    if not image_files:\n",
    "        print(\"No processed images found. Please run the preprocessing first.\")\n",
    "        return\n",
    "    \n",
    "    sample_file = image_files[0]\n",
    "    base_name = sample_file.stem.replace(\"_center_crop\", \"\")\n",
    "    \n",
    "    # Load different versions\n",
    "    center_crop_path = sample_dir / f\"{base_name}_center_crop.png\"\n",
    "    padded_path = sample_dir / f\"{base_name}_padded_256.png\"\n",
    "    high_res_path = sample_dir / f\"{base_name}_high_res_512.png\"\n",
    "    \n",
    "    images = []\n",
    "    titles = []\n",
    "    \n",
    "    if center_crop_path.exists():\n",
    "        img = cv2.imread(str(center_crop_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        images.append(img)\n",
    "        titles.append(f\"Center Crop\\n{img.shape[0]}x{img.shape[1]}\")\n",
    "    \n",
    "    if padded_path.exists():\n",
    "        img = cv2.imread(str(padded_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        images.append(img)\n",
    "        titles.append(f\"Padded Square\\n{img.shape[0]}x{img.shape[1]}\")\n",
    "    \n",
    "    if high_res_path.exists():\n",
    "        img = cv2.imread(str(high_res_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        images.append(img)\n",
    "        titles.append(f\"High Resolution\\n{img.shape[0]}x{img.shape[1]}\")\n",
    "    \n",
    "    # Create comparison plot\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(15, 5))\n",
    "    if len(images) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, (img, title) in enumerate(zip(images, titles)):\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(title)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(f\"Preprocessing Methods Comparison\\nSample: {base_name}\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\nüìä Image Statistics for {base_name}:\")\n",
    "    for img, title in zip(images, titles):\n",
    "        print(f\"  {title.split()[0]} {title.split()[1]}: Shape {img.shape}, \"\n",
    "              f\"Mean brightness: {np.mean(img):.1f}, Std: {np.std(img):.1f}\")\n",
    "\n",
    "# Run the comparison\n",
    "compare_preprocessing_methods()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a874559",
   "metadata": {},
   "source": [
    "## Image Preprocessing Improvements\n",
    "\n",
    "The enhanced preprocessing pipeline includes several key improvements:\n",
    "\n",
    "### üîç **Resolution Enhancement Techniques:**\n",
    "1. **CLAHE (Contrast Limited Adaptive Histogram Equalization)**: Improves local contrast while preventing over-amplification\n",
    "2. **Unsharp Masking**: Enhances image sharpness and edge definition\n",
    "3. **Bilateral Filtering**: Reduces noise while preserving important edges\n",
    "\n",
    "### üìê **Aspect Ratio Preservation:**\n",
    "- **Center Cropping**: Extracts the central square region, maintaining original pixel resolution\n",
    "- **Padding Method**: Adds padding to make images square without distortion\n",
    "- **No Stretching**: Eliminates distortion that occurs with direct resizing\n",
    "\n",
    "### üìè **Multiple Output Sizes:**\n",
    "- **224x224**: Standard size for many deep learning models\n",
    "- **256x256**: Balanced size with more detail preservation\n",
    "- **512x512**: High-resolution version for detailed analysis\n",
    "\n",
    "### ‚úÖ **Benefits:**\n",
    "- Maintains cell morphology and relative sizes\n",
    "- Improves image quality for better feature extraction\n",
    "- Provides multiple resolution options for different model requirements\n",
    "- Preserves spatial relationships critical for medical image analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
